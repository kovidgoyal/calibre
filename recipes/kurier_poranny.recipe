import re
from calibre.web.feeds.news import BasicNewsRecipe
from calibre.ebooks.BeautifulSoup import Comment

class KurierPoranny(BasicNewsRecipe):
    title          = u'Kurier Poranny'
    __author__        = 'fenuks'
    description   = u'Kurier Poranny | poranny.pl - portal miejski Białegostoku,informacje,wydarzenia'
    category       = 'newspaper'
    language       = 'pl'
    encoding = 'iso-8859-2'
    extra_css = 'ul {list-style: none; padding:0; margin:0;}'
    INDEX = 'http://www.poranny.pl'
    masthead_url = INDEX + '/images/top_logo.png'
    oldest_article = 7
    max_articles_per_feed = 100
    remove_empty_feeds = True
    no_stylesheets = True
    ignore_duplicate_articles = {'title', 'url'}
    use_embedded_content = False

    feeds          = [(u'Wszystkie', u'http://www.poranny.pl/rss.xml'), 
                      (u'Białystok', u'http://www.poranny.pl/bialystok.xml'), 
                      (u'Bielsk Podlaski', u'http://www.poranny.pl/bielskpodlaski.xml'), 
                      (u'Czarna Białostocka', u'http://www.poranny.pl/czarnabialostocka.xml'), 
                      (u'Hajnówka', u'http://www.poranny.pl/hajnowka.xml'), 
                      (u'Łapy', u'http://www.poranny.pl/lapy.xml'), 
                      (u'Sokółka', u'http://www.poranny.pl/sokolka.xml'), 
                      (u'Supraśl', u'http://www.poranny.pl/suprasl.xml'), 
                      (u'Wasilków', u'http://www.poranny.pl/wasilkow.xml'), 
                      (u'Sport', u'http://www.poranny.pl/sport.xml'), 
                      (u'Praca', u'http://www.poranny.pl/praca.xml'), 
                      (u'Kultura', u'http://www.poranny.pl/kultura.xml'), 
                      (u'Dom', u'http://www.poranny.pl/dom.xml'), 
                      (u'Auto', u'http://www.poranny.pl/auto.xml'), 
                      (u'Polityka', u'http://www.poranny.pl/polityka.xml')]

    keep_only_tags = [dict(id='article')]

    def get_cover_url(self):
        soup = self.index_to_soup(self.INDEX + '/apps/pbcs.dll/section?Category=JEDYNKI')
        nexturl = self.INDEX + soup.find(id='covers').find('a')['href']
        soup = self.index_to_soup(nexturl)
        self.cover_url = self.INDEX + soup.find(id='cover').find(name='img')['src']
        return getattr(self, 'cover_url', self.cover_url)

    def decode_feedportal_url(self, url):
        link = url.rpartition('l/0L0S')[2][:-12]
        replaces = (('0B', '.'), ('0C', '/'), ('0H', ','), ('0D', '?'), ('0F', '='), ('0A', '0'), ('0I', '_'))
        for t in replaces:
            link = link.replace(*t)
        return 'http://' + link

    def print_version(self, url):
        return self.decode_feedportal_url(url) + '&Template=printpicart'
