from calibre.web.feeds.recipes import BasicNewsRecipe
from collections import OrderedDict

class BusinessWeekMagazine(BasicNewsRecipe):

    title       = 'Business Week Magazine'
    __author__  = 'Rick Shang'

    description = 'A renowned business publication. Business news, trends and profiles of successful businesspeople.'
    language = 'en'
    category = 'news'
    encoding = 'UTF-8'
    keep_only_tags = [
            dict(name='div', attrs={'id':'article_body_container'}),
            ]
    remove_tags = [dict(name='ui'),dict(name='li')]
    no_javascript = True
    no_stylesheets = True

    cover_url             = 'http://images.businessweek.com/mz/covers/current_120x160.jpg'

    def parse_index(self):

        #Go to the issue
        soup = self.index_to_soup('http://www.businessweek.com/magazine/news/articles/business_news.htm')

        #Find date
        mag=soup.find('h2',text='Magazine')
        dates=self.tag_to_string(mag.findNext('h3'))
        self.timefmt = u' [%s]'%dates

        #Go to the main body
        div0 = soup.find ('div', attrs={'class':'column left'})
        section_title = ''
        feeds = OrderedDict()
        articles = []
        for div in div0.findAll('a'):
            section_title = self.tag_to_string(div.findPrevious('h3')).strip()
            self.log('Processing section:', section_title)
            title=self.tag_to_string(div).strip()
            url=div['href']
            soup0 = self.index_to_soup(url)
            urlprint=soup0.find('li', attrs={'class':'print'}).a['href']
            articles.append({'title':title, 'url':urlprint, 'description':'', 'date':''})


        if articles:
            if section_title not in feeds:
                feeds[section_title] = []
            feeds[section_title] += articles
        div1 = soup.find ('div', attrs={'class':'column center'})
        section_title = ''
        articles = []
        for div in div1.findAll('a'):
            desc=self.tag_to_string(div.findNext('p')).strip()
            section_title = self.tag_to_string(div.findPrevious('h3')).strip()
            self.log('Processing section:', section_title)
            title=self.tag_to_string(div).strip()
            url=div['href']
            soup0 = self.index_to_soup(url)
            urlprint=soup0.find('li', attrs={'class':'print'}).a['href']
            articles.append({'title':title, 'url':urlprint, 'description':desc, 'date':''})

        if articles:
            if section_title not in feeds:
                feeds[section_title] = []
            feeds[section_title] += articles
        ans = [(key, val) for key, val in feeds.iteritems()]
        return ans

