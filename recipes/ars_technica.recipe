__license__ = 'GPL v3'
__copyright__ = '2008-2012, Darko Miletic <darko.miletic at gmail.com>'
'''
arstechnica.com
'''

import re
from calibre.web.feeds.news import BasicNewsRecipe
from calibre.ebooks.BeautifulSoup import BeautifulSoup


class ArsTechnica(BasicNewsRecipe):
    title = u'Ars Technica'
    language = 'en'
    __author__ = 'Darko Miletic, Sujata Raman, Alexis Rohou, Tom Sparks'
    description = 'Ars Technica: Serving the technologist for 1.2 decades'
    publisher = 'Conde Nast Publications'
    oldest_article = 5
    max_articles_per_feed = 100
    no_stylesheets = True
    encoding = 'utf-8'
    use_embedded_content = False
    remove_empty_feeds = True
    extra_css             = '''
    body {font-family: Arial,sans-serif}
    .heading{font-family: "Times New Roman",serif}
    .byline{font-weight: bold; line-height: 1em; font-size: 0.625em; text-decoration: none}
    img{display: block}
    .caption-text{font-size:small; font-style:italic}
    .caption-byline{font-size:small; font-style:italic; font-weight:bold}
    .video, .page-numbers, .story-sidebar { display: none }
    .image { display: block }
    '''

    keep_only_tags = [
        dict(itemprop=['headline', 'description']), dict(attrs={'class': ['post-meta', 'article-guts', 'standalone']})
    ]

    remove_tags = [
        dict(name=['object', 'link', 'embed', 'iframe', 'meta']),
        dict(attrs={'class': ['video', 'corner-info', 'article-expander']}),
        dict(id=['social-left', 'article-footer-wrap']),
        dict(name='nav', attrs={'class': 'subheading'}),
    ]
    remove_attributes = ['lang', 'style']

    feeds = [
        (u'Ars Features (All our long-form feature articles)', u'http://feeds.arstechnica.com/arstechnica/features'),
        (u'Technology Lab (Information Technology)', u'http://feeds.arstechnica.com/arstechnica/technology-lab'),
        (u'Gear & Gadgets', u'http://feeds.arstechnica.com/arstechnica/gadgets'),
        (u'Ministry of Innovation (Business of Technology)', u'http://feeds.arstechnica.com/arstechnica/business'),
        (u'Risk Assessment (Security & Hacktivism)', u'http://feeds.arstechnica.com/arstechnica/security'),
        (u'Law & Disorder (Civilizations & Discontents)', u'http://feeds.arstechnica.com/arstechnica/tech-policy'),
        (u'Infinite Loop (Apple Ecosystem)', u'http://feeds.arstechnica.com/arstechnica/apple'),
        (u'Opposable Thumbs (Gaming & Entertainment)', u'http://feeds.arstechnica.com/arstechnica/gaming'),
        (u'Scientific Method (Science & Exploration)', u'http://feeds.arstechnica.com/arstechnica/science'),
        (u'Multiverse (Exploratoins & Meditations on Sci-Fi)', u'http://feeds.arstechnica.com/arstechnica/multiverse'),
        (u'Cars Technica (All Things Automotive)', u'http://feeds.arstechnica.com/arstechnica/cars'),
        (u'Staff Blogs (From the Minds of Ars)', u'http://feeds.arstechnica.com/arstechnica/staff-blogs')
    ]

    def append_page(self, soup, appendtag, position):
        pager = soup.find(attrs={'class': 'numbers'})
        if pager:
            nexttag = pager.find(attrs={'class': 'next'})
            if nexttag:
                nurl = nexttag.parent['href']
                rawc = self.index_to_soup(nurl, True)
                soup2 = BeautifulSoup(rawc, fromEncoding=self.encoding)
                texttag = soup2.find(attrs={'class': 'article-guts'})
                if texttag is not None:
                    newpos = len(texttag.contents)
                    self.append_page(soup2, texttag, newpos)
                    texttag.extract()
                    pager.extract()
                    appendtag.insert(position, texttag)

    def preprocess_html(self, soup):
        self.append_page(soup, soup.body, 3)
        for item in soup.findAll('a'):
            limg = item.find('img')
            if item.string is not None:
                str = item.string
                item.replaceWith(str)
            else:
                if limg:
                    item.name = 'div'
                    item.attrs = []
                else:
                    str = self.tag_to_string(item)
                    item.replaceWith(str)
        for div in soup.findAll('div', attrs={'class':'image', 'style':lambda x: x and 'background-image' in x}):
            url = re.search(r'''url\(['"]?([^'")]+)''', div['style'])
            if url is not None:
                div.name = 'img'
                div['src'] = url.group(1)
                div['style'] = ''
        return soup

    def preprocess_raw_html(self, raw, url):
        return '<html><head>' + raw[raw.find('</head>'):]
