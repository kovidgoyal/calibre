#!/usr/bin/env python
from calibre.web.feeds.news import BasicNewsRecipe, classes

def absurl(url):
    if url.startswith('/'):
        url = 'https://www.science.org' + url
    return url


class scienceadv(BasicNewsRecipe):
    title = 'Science Robotics'
    __author__ = 'unkn0wn'
    description = (
        'Science Robotics provides a much-needed forum for the latest technological advances and for the critical social, ethical '
        'and policy issues surrounding robotics. Science Robotics caters to both researchers and general stakeholders. It is multidisciplinary, '
        'covering the traditional disciplines of robotics, as well as emerging trends such as advanced materials and bio-inspired designs; it covers '
        'all scales, from very large systems to micro/nano robots; its scope is broad, addressing both theoretical advances and practical applications.'
    )
    encoding = 'utf-8'
    no_javascript = True
    no_stylesheets = True
    remove_attributes = ['style', 'height', 'width']
    masthead_url = 'https://www.science.org/pb-assets/images/logos/scirobotics-logo-1620488350107.svg'
    language = 'en'
    simultaneous_downloads = 1
    browser_type = 'qt'

    extra_css = '''
        .news-article__figure__caption {font-size:small; text-align:center;}
        .core-self-citation, .meta-panel__left-content, .news-article__hero__top-meta {font-size:small;}
        .contributors, .news-article__hero__bottom-meta, #bibliography, #elettersSection {font-size:small;}
        img {display:block; margin:0 auto;}
        .core-lede {font-style:italic; color:#202020;}
    '''

    ignore_duplicate_articles = {'url'}

    keep_only_tags = [
        classes('meta-panel__left-content news-article__hero__info news-article__hero__figure bodySection'),
        dict(name='h1', attrs={'property':'name'}),
        dict(name='div', **classes('core-lede contributors core-self-citation')),
        dict(attrs={'data-core-wrapper':'content'})
    ]

    remove_tags = [
        classes('pb-ad news-article__hero__scroller news-article__version-of-story')
    ]

    recipe_specific_options = {
        'issue': {
            'short': 'Enter the Issue Number you want to download\n(Vol/Issue format)',
            'long': 'For example, 385/6710',
            'default': 'current'
        }
    }

    def preprocess_html(self, soup):
        for p in soup.findAll(attrs={'role':'paragraph'}):
            p.name = 'p'
            p.attrs = {}
        return soup

    def parse_index(self):
        issue_url = 'https://www.science.org/toc/scirobotics/current'
        d = self.recipe_specific_options.get('issue')
        if d and isinstance(d, str):
            issue_url = 'https://www.science.org/toc/scirobotics/' + d

        soup = self.index_to_soup(issue_url)
        tme = soup.find(**classes('journal-issue__vol'))
        if tme:
            self.timefmt = ' [%s]' % self.tag_to_string(tme).strip().replace('|', ' | ')
        det = soup.find(attrs={'id':'journal-issue-details'})
        if det:
            self.description = self.tag_to_string(det).strip()
        cov = soup.find(**classes('cover-image__image'))
        if cov:
            self.cover_url = absurl(cov.img['src'])

        feeds = []

        div = soup.find('div', attrs={'class':'toc__body'})
        for sec in div.findAll('section', **classes('toc__section')):
            name = sec.find(**classes('sidebar-article-title--decorated'))
            section = self.tag_to_string(name).strip()
            self.log(section)

            articles = []

            for card in sec.findAll(**classes('card-header')):
                ti = card.find(**classes('article-title'))
                url = absurl(ti.a['href'])
                title = self.tag_to_string(ti).strip()
                desc = ''
                meta = card.find(**classes('card-meta'))
                if meta:
                    desc = self.tag_to_string(meta).strip()
                self.log('            ', title, '\n\t', desc, '\n\t\t', url)
                articles.append({'title': title, 'description':desc, 'url': url})
            feeds.append((section, articles))
        return feeds
